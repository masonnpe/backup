 ## 为什么要分库分表

数据量越大，请求量越大，单个数据库扛不住请求，所以数据库做读写分离分担压力。但数据库读写分离总是会受到数据库大小的限制，一旦数据库过于庞大，尤其是写入过于频繁，很难由一台主机支撑，面临到扩展瓶颈。需要对数据进行切分，将我们存放在同一个数据库中的数据分散存放到多个数据库上面 。另外单表数据量太大，sql执行的性能低。分库与分表的目的在于，减小数据库的单库单表负担，提高查询性能，缩短查询时间 

### 分表

面对上千万甚至上亿的数据，查询一次所花费的时间很长长，如果有联合查询的情况下，甚至可能会成为很大的瓶颈。此外，MySQL 存在表锁和行锁，因此更新表数据可能会引起表锁或者行锁，这样也会导致其他操作等待，甚至死锁问题。

通过分表，可以减少数据库的单表负担，将压力分散到不同的表上，同时因为不同的表上的数据量少了，起到提高查询性能，缩短查询时间的作用，此外，可以很大的缓解表锁的问题。

分表策略可以归纳为垂直拆分和水平拆分。

**垂直拆分**，把表的字段进行拆分，即一张字段比较多的表拆分为多张表，这样使得行数据变小。一方面，可以减少客户端程序和数据库之间的网络传输的字节数，因为生产环境共享同一个网络带宽，随着并发查询的增多，有可能造成带宽瓶颈从而造成阻塞。另一方面，一个数据块能存放更多的数据，在查询时就会减少 I/O 次数。举个例子，假设用户表中有一个字段是家庭地址，这个字段是可选字段，在数据库操作的时候除了个人信息外，并不需要经常读取或是更改这个字段的值。在这种情况下，更建议把它拆分到另外一个表，从而提高性能。

垂直拆分建议：

- 将不常用的字段单独拆分到另外一张扩展表，例如前面讲解到的用户家庭地址，这个字段是可选字段，在数据库操作的时候除了个人信息外，并不需要经常读取或是更改这个字段的值。
- 将大文本的字段单独拆分到另外一张扩展表，例如 BLOB 和 TEXT 字符串类型的字段，以及 TINYBLOB、 MEDIUMBLOB、 LONGBLOB、 TINYTEXT、 MEDIUMTEXT、 LONGTEXT字符串类型。这样可以减少客户端程序和数据库之间的网络传输的字节数。
- 将不经常修改的字段放在同一张表中，将经常改变的字段放在另一张表中。举个例子，假设用户表的设计中，还存在“最后登录时间”字段，每次用户登录时会被更新。这张用户表会存在频繁的更新操作，此外，每次更新时会导致该表的查询缓存被清空。所以，可以把这个字段放到另一个表中，这样查询缓存会增加很多性能。
- 对于需要经常关联查询的字段，建议放在同一张表中。不然在联合查询的情况下，会带来数据库额外压力。

**水平拆分**，把表的行进行拆分。因为表的行数超过几百万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。水平拆分，有许多策略，例如，取模分表，时间维度分表，以及自定义 Hash 分表，例如用户 ID 维度分表等。在不同策略分表情况下，根据各自的策略写入与读取。

实际上，**垂直拆分后的表依然存在单表数据量过大的问题，需要进行水平拆分**。因此，实际情况中，水平拆分往往会和垂直拆分结合使用。假设，随着用户数的不断增加，用户表单表存在上千万的数据，这时可以把一张用户表的数据拆成多张用户表来存放。

常见的水平分表策略归纳起来，可以总结为随机分表和连续分表两种情况。例如，取模分表就属于随机分表，而时间维度分表则属于连续分表。

连续分表可以快速定位到表进行高效查询，大多数情况下，可以有效避免跨表查询。如果想扩展，只需要添加额外的分表就可以了，无需对其他分表的数据进行数据迁移。但是，连续分表有可能存在数据热点的问题，有些表可能会被频繁地查询从而造成较大压力，热数据的表就成为了整个库的瓶颈，而有些表可能存的是历史数据，很少需要被查询到。

随机分表是遵循规则策略进行写入与读取，而不是真正意义上的随机。通常，采用取模分表或者自定义 Hash 分表的方式进行水平拆分。随机分表的数据相对比较均匀，不容易出现热点和并发访问的瓶颈。但是，分表扩展需要迁移旧的数据。此外，随机分表比较容易面临跨表查询的复杂问题。

对于日志场景，可以考虑根据时间维度分表，例如年份维度分表或者月份维度分表，在日志记录表的名字中包含年份和月份的信息，例如 log_2017_01，这样可以在已经没有新增操作的历史表上做频繁地查询操作，而不会影响时间维度分表上新增操作。

对于海量用户场景，可以考虑**取模**分表，数据相对比较均匀，不容易出现热点和并发访问的瓶颈。

对于租户场景，可以考虑租户维度分表，不同的租户数据独立，而不应该在每张表中添加租户 ID，这是一个不错的选择。

### 分库概述

库内分表，仅仅是解决了单表数据过大的问题，但并没有把单表的数据分散到不同的物理机上，因此并不能减轻 MySQL 服务器的压力，仍然存在同一个物理机上的资源竞争和瓶颈，包括 CPU、内存、磁盘 IO、网络带宽等。

分库策略也可以归纳为垂直拆分和水平拆分。

**垂直拆分**，按照业务和功能划分，把数据分别放到不同的数据库中。举个例子，可以划分资讯库、百科库等。

**水平拆分**，把一张表的数据划分到不同的数据库，两个数据库的表结构一样。实际上，水平分库与水平分表类似，水平拆分有许多策略，例如，取模分库，自定义 Hash 分库等，在不同策略分库情况下，根据各自的策略写入与读取。举个例子，随着业务的增长，资讯库的单表数据过大，此时采取水平拆分策略，根据取模分库。

### 伴随的问题

**主键ID**

数据库自增id 数据库维护一个Sequence表，并发有瓶颈

uuid 作为主键性能太差了，不适合

系统当前时间 高并发有重复现象  但是可以用时间戳 + 用户id + 业务含义编码

snowflake算法 twitter开源的分布式id生成算法，就是把一个64位的long型的id，1个bit是不用的，用其中的41 bit作为毫秒数，用10 bit作为工作机器id(如果多机房可以用 5bit机器id+5bit机房id)，12 bit作为序列号

![](http://wx3.sinaimg.cn/large/007iUdjSgy1fxyap2u5xtj30sd09mt9o.jpg)

**跨节点join的问题**

1. 数据库端MySQL的Federated存储引擎可以解决跨节点join
2. 普遍做法是分两次查询实现，在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据，对性能产生影响，但可以接受。

**跨节点count、order by、group by以及聚合函数**

分别在各个节点上得到结果后在应用程序端进行合并，和join不同的是每个结点的查询可以并行执行

**跨节点的排序分页**

分页时一般需要按照指定字段进行排序，当排序字段就是分片字段的时候，可以通过分片规则比较容易定位到指定的分片节点，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将返回的结果集进行汇总和再次排序，最后再返回给用户

**还有数据迁移，容量规划，扩容等问题**

## 分库分表中间件

**sharding-jdbc**：属于client层方案，支持分库分表、读写分离、分布式id生成、柔性事务（最大努力送达型事务、TCC事务）。

优点：不用部署，运维成本低，不需要代理层的二次转发请求，性能很高

缺点：如果需要升级，各个系统都重新升级版本再发布，各个系统都需要耦合sharding-jdbc的依赖

**mycat**：基于cobar改造的，属于proxy层方案，支持的功能非常完善。

优点：对于各个项目是透明的，如果需要升级之类的都是自己中间件那里搞就行了

缺点：需要部署，运维一套中间件，运维成本高

## 如何对数据库进行拆分

### 垂直拆分

可以根据字段的访问频率

### 水平拆分

**range**  

优点：扩容的时候很容易，只需要按时准备好一个库，比如一个月订单写一个数据库，到了一个新的月份的时候写新库

缺点：大部分的请求，都是访问最新的数据。用户几乎只会查看最近的几个订单

实际生产用range，要看场景，用户不是仅仅访问最新的数据，而是均匀的访问现在的数据以及历史的数据

**hash**  

优点：可以平均分配没给库的数据量和请求压力

缺点：扩容起来比较麻烦，会有一个数据迁移的过程

## 实践

对于一个尚未进行分库分表的系统，要切换到分库分表上，有几个方案

1. 停机修改配置写，服务会不可用一段时间
2. 取老库的备份，写入新库，在这期间的增删改，以日志的形式存着，备份的数据写完了接着写日志里的知道结束
3. 线上系统里面，所有写库的地方，除了对老库增删改，都加上对新库的增删改，同时写老库和新库。然后用导数据的工具，读老库数据写新库，写的时候要根据last_modified这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。

动态扩容缩容

1. 利用32 * 32来分库分表，即分为32个库，每个库里一个表分为32张表，一共就是1024张表。比如对订单表进行拆分，orderId mod 32 确定库的索引       orderId / 32 mod 32 = 确定表的索引
2. 扩容的时候，申请增加更多的数据库服务器，装好mysql，倍数扩容，4台服务器，扩到8台服务器，16台服务器
3.  将原先数据库服务器的库，迁移到新的数据库服务器上去
4. 修改一下配置，调整迁移的库所在数据库服务器的地址，重新发布系统，上线，原先的路由规则变都不用变，直接可以基于2倍的数据库服务器的资源，继续进行线上系统的提供服务

```java
public class IdWorker {

    private long twepoch = 1288834974657L;

    private long workerIdBits = 5L;

    private long datacenterIdBits = 5L;

    private long maxWorkerId = -1L ^ (-1L << workerIdBits); // 这个是二进制运算，就是5 bit最多只能有31个数字，也就是说机器id最多只能是32以内

    private long maxDatacenterId = -1L ^ (-1L << datacenterIdBits); // 这个是一个意思，就是5 bit最多只能有31个数字，机房id最多只能是32以内

    private long workerId;// 机器

    private long datacenterId;// 机房

    private long sequence;

    private long sequenceBits = 12L;

    private long workerIdShift = sequenceBits;

    private long datacenterIdShift = sequenceBits + workerIdBits;

    private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;

    private long sequenceMask = -1L ^ (-1L << sequenceBits);

    private long lastTimestamp = -1L;

    public IdWorker(long workerId, long datacenterId, long sequence) {
        if (workerId > maxWorkerId || workerId < 0) {
            throw new IllegalArgumentException(String.format("worker Id can't be greater than %d or less than 0", maxWorkerId));
        }

        if (datacenterId > maxDatacenterId || datacenterId < 0) {
            throw new IllegalArgumentException(String.format("datacenter Id can't be greater than %d or less than 0", maxDatacenterId));
        }
        System.out.printf("worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d",
                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);
        this.workerId = workerId;
        this.datacenterId = datacenterId;
        this.sequence = sequence;

    }

    public long getWorkerId() {
        return workerId;
    }


    public long getDatacenterId() {
        return datacenterId;
    }


    public long getTimestamp() {
        return System.currentTimeMillis();
    }

    public synchronized long nextId() {

        // 这儿就是获取当前时间戳，单位是毫秒
        long timestamp = timeGen();
        if (timestamp < lastTimestamp) {
            System.err.printf("clock is moving backwards.  Rejecting requests until %d.", lastTimestamp);
            throw new RuntimeException(String.format("Clock moved backwards.  Refusing to generate id for %d milliseconds",
                    lastTimestamp - timestamp));
        }

        if (lastTimestamp == timestamp) {
            //这个意思是说一个毫秒内最多只能有4096个数字，无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围
            sequence = (sequence + 1) & sequenceMask;
            if (sequence == 0) {
                timestamp = tilNextMillis(lastTimestamp);
            }
        } else {
            sequence = 0;
        }
        // 这儿记录一下最近一次生成id的时间戳，单位是毫秒
        lastTimestamp = timestamp;
        // 这儿就是将时间戳左移，放到41 bit那儿；将机房id左移放到5 bit那儿；将机器id左移放到5 bit那儿；将序号放最后10 bit；最后拼接起来成一个64 bit的二进制数字，转换成10进制就是个long型
        return ((timestamp - twepoch) << timestampLeftShift) |
                (datacenterId << datacenterIdShift) |
                (workerId << workerIdShift) |
                sequence;
    }


    private long tilNextMillis(long lastTimestamp) {
        long timestamp = timeGen();
        while (timestamp <= lastTimestamp) {
            timestamp = timeGen();
        }
        return timestamp;
    }


    private long timeGen() {
        return System.currentTimeMillis();
    }

    public static void main(String[] args) {
        IdWorker worker = new IdWorker(1, 1, 1);
        for (int i = 0; i < 30; i++) {
            System.out.println(worker.nextId());
        }
    }
}
```



 